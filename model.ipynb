{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59edf9ba-3ab8-4ecb-9a71-26b1bfa4ed94",
   "metadata": {},
   "source": [
    "### Бейзлайн модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81ac46-3233-4b03-8ede-efb73a45994f",
   "metadata": {},
   "source": [
    "**Импорт библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b35fdc9-dc69-4c0f-afad-8995b0288fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c47a898-8649-4066-9794-292bb25dd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import RobertaTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import tensorflow_text as text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3e821-2128-4448-bfe3-c1629d5836b5",
   "metadata": {},
   "source": [
    "**Загружаем предобработанные данные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365f6da2-e5e8-4476-b9f1-90fb816887c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d8613-8d51-4f96-9bfd-fbe9dd52dc02",
   "metadata": {},
   "source": [
    "**Дообучаем `DeBERTa`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7bc6a1-32fb-4deb-b06e-eb1c6c839cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"/kaggle/input/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16603e-2a8d-4b9e-ae6a-82fa22372a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_truncate(text, max_length=512):\n",
    "    # Tokenize and truncate\n",
    "    tokens = tokenizer.tokenize(text)[:max_length]  # leaving space for special tokens\n",
    "    # Add the special tokens\n",
    "    \n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8984c3f-34c7-4348-8dae-7985f551bb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c6bf5f-9ad7-4a1f-872c-8243dcc00f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.rename(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a047b5-775e-4d9d-8826-2b6624d93473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"tokens\"] = train_data.text.progress_apply(lambda x: tokenize_and_truncate(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python, hw + experiments",
   "language": "python",
   "name": "hw-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
