### LLM detection

- `dataset.ipynb`: преобразование датасета
- `eda.ipynb`: EDA
- `model.ipynb`: эксперимент с дообучением модели

**25.01**

TODO: пропишу прогресс позже по каждому ноутбуку

**22.01**

Доработал ноутбуки, созонились обсудить промежуточные результаты

**checkpoint2**

Добавил ноутбуки `eda.ipynb`, `model.ipynb`

**checkpoint1**

Данные устроены следующим образом:
1. Есть датасет no robots, он содержит промпты и примеры человеческих ответов на них
2. На его основе собирается датасет beemo: на каждый промпт ллмка выдает ответ + ее ответ редактирует человек (через Толоку)
3. По итогу получается 3 класса: написано человеком + написано ллм + написано ллм, отредактированно человеком 

В ноутбуке `dataset.ipynb` я сделал следующее:
1. Скачал оба датасета
2. Показал, что они строятся на основе одинаковых промптов
3. Вывел нужные нам колонки
4. Привел к виду, который подходит для обучения модели

TODO: стоит ли дообогатить 3 класс, когда `human_output` редактируется LLM? Пример: попросить LLM написать свое письмо в более формальном стиле.
