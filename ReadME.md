### LLM detection

- `dataset.ipynb`: преобразование датасета
- `eda.ipynb`: EDA
- `model.ipynb`: эксперимент с дообучением модели

**25.01**

1. Посмотрел, пишет ли LLM более развернуто (без сокращений). Все-таки нет. При этом в репозитории датасета `beemo` написано, что под каждый промпт выбирается одна из 10 случайная LLMка для генерации, видимо, для какого-то обобщенного ответа LLM без привязки к конкретной модели. Какие это нам сложности может создать? Добавил в файл `dataset.ipynb` распределение названий моделей (получилось равномерное).
2. Обновил `eda.ipynb`, добавил `*` в анализ символов (LLM чаще использует), убрал `'` при обработке. В итоге различия между LLM и человеком не подтвердились. А вот `*` возможно не стоит убирать из символов, чтобы это было как фича LLMки?
3. Попробовал через Kaggle Notebooks аугмееентацию с помощью `API Groq`. Минут за 20 нагенерировал 200 текстов, а дальше токены закончились. Можно ли как-то ускорить процесс: использовать что-то другое, например? 
4. Посмотрел на тексты с пересечением. В нем особо выделялись слова `help, life` у LLM, в то время как у людей чисто нейтральные глаголы и артикли. Выяснилось, что LLM просто везде любит пихать определенный оборот. Вроде явно на конкретной теме не фокусируется.
5. Добавил подсчет метрик в `eda.ipynb`. TODO: есть ли смысл считать perplexity, если у нас разные модели?
6. Обновил в `model.ipynb` разделение на `train/val/test`
7. Провел доп эксперименты с `tf-IDF, SentenceTransformers`, все ли ок? Почему-то `optuna` не смогла построить что-то, кроме иф-елс пней для катбуста.
8. Добавил файл `eda2.ipynb` с EDA для неспрогнозированных кейсов. Вывод: удаление звзедочек и прочих характерных для LLM вещей очень сильно мешает, не получилось распознать почти ничего.

**22.01**

Доработал ноутбуки, созонились обсудить промежуточные результаты

**checkpoint2**

Добавил ноутбуки `eda.ipynb`, `model.ipynb`

**checkpoint1**

Данные устроены следующим образом:
1. Есть датасет no robots, он содержит промпты и примеры человеческих ответов на них
2. На его основе собирается датасет beemo: на каждый промпт ллмка выдает ответ + ее ответ редактирует человек (через Толоку)
3. По итогу получается 3 класса: написано человеком + написано ллм + написано ллм, отредактированно человеком 

В ноутбуке `dataset.ipynb` я сделал следующее:
1. Скачал оба датасета
2. Показал, что они строятся на основе одинаковых промптов
3. Вывел нужные нам колонки
4. Привел к виду, который подходит для обучения модели

TODO: стоит ли дообогатить 3 класс, когда `human_output` редактируется LLM? Пример: попросить LLM написать свое письмо в более формальном стиле.
