### LLM detection

- `dataset.ipynb`: преобразование датасета
- `eda.ipynb`: EDA
- `model.ipynb`: эксперимент с дообучением модели

**checkpoint2**

TODO: обсудить промежуточные результаты и к концу недели получить финальный вариант ноутбуков `eda.ipynb` и `model.ipynb`

**checkpoint1**

Данные устроены следующим образом:
1. Есть датасет no robots, он содержит промпты и примеры человеческих ответов на них
2. На его основе собирается датасет beemo: на каждый промпт ллмка выдает ответ + ее ответ редактирует человек (через Толоку)
3. По итогу получается 3 класса: написано человеком + написано ллм + написано ллм, отредактированно человеком 

В ноутбуке `dataset.ipynb` я сделал следующее:
1. Скачал оба датасета
2. Показал, что они строятся на основе одинаковых промптов
3. Вывел нужные нам колонки
4. Привел к виду, который подходит для обучения модели

TODO: стоит ли дообогатить 3 класс, когда `human_output` редактируется LLM? Пример: попросить LLM написать свое письмо в более формальном стиле.
